{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750a2a31",
   "metadata": {},
   "source": [
    "# Experimenting With 1D CNN on Baumhofer Data\n",
    "All models and their variants should be stored in ./ml_utils/models.py<br>\n",
    "Opening a new notebook for working with the model, separate to the data pre-processing, helps keep things clean and easily accessible for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cb7ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from ml_utils import models, tools\n",
    "from baumhofer_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c138792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data we will need\n",
    "with open(\"./data/X_array_first_100.pkl\", \"rb\") as a_file:\n",
    "    X = pickle.load(a_file)\n",
    "\n",
    "with open(\"./data/index_first_100.pkl\", \"rb\") as a_file:\n",
    "    index = pickle.load(a_file)\n",
    "\n",
    "with open(\"./data/capacity_target_df_first_100.pkl\", \"rb\") as a_file:\n",
    "    cap_df = pickle.load(a_file)\n",
    "\n",
    "with open(\"./data/y_array_first_100.pkl\", \"rb\") as a_file:\n",
    "    y_arr = pickle.load(a_file)\n",
    "\n",
    "# Change the path for this one so it points to your local copy - too big for GitHub\n",
    "with open(\"E:/new_german_data/code/processed_data/baumhofer_first_100_cycles.pkl\", \"rb\") as a_file:\n",
    "    data = pickle.load(a_file)\n",
    "\n",
    "cells = list(data.keys())\n",
    "index_cells = np.array([name.split(\"_\")[0] for name in index])\n",
    "    \n",
    "del a_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e57245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to reshape the data so it's the appropriate shape for 1D CNN / LSTM models.\n",
    "# This will accept arbitrary numbers of features\n",
    "\n",
    "def reshape_for_model(X_arr, to_plot=False):\n",
    "    # Get the shape of the data prior to reshaping for model\n",
    "    features, samples, timesteps = X_arr.shape\n",
    "    \n",
    "    # Instead of creating a new array where we assume a number of features,\n",
    "    # we stack all features present in X_arr.\n",
    "    X_reshaped = np.array([np.vstack(\n",
    "                            [np.vstack(\n",
    "                                [X_arr[j, i, :] for j in range(features)]\n",
    "                            )]).T\n",
    "                           for i in range(samples)])\n",
    "        \n",
    "    if to_plot:\n",
    "        # Plot a random selection of instances to check they look OK\n",
    "        indices = np.random.randint(0, samples, size=25)\n",
    "        fig, ax = plt.subplots(5,5)\n",
    "        for subplot, sample in enumerate(indices):\n",
    "            ax.flatten()[subplot].plot(X_reshaped[sample,:,1])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    return X_reshaped\n",
    "\n",
    "\n",
    "X = reshape_for_model(X, to_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ccae940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a test set back and use the rest for k-fold\n",
    "train_cells, test_cells = train_test_split(cells, train_size=0.9, random_state=31)\n",
    "train_cells = np.array(train_cells)\n",
    "test_cells = np.array(test_cells)\n",
    "\n",
    "index_train = np.in1d(index_cells, train_cells)\n",
    "index_test = np.in1d(index_cells, test_cells)\n",
    "\n",
    "X_train, X_test = X[index_train], X[index_test]\n",
    "y_train, y_test = y_arr[index_train], y_arr[index_test]\n",
    "\n",
    "# Get the index arrays for k-fold\n",
    "X_train_index = np.array([val for val in index_cells if val in train_cells])\n",
    "X_test_index = np.array([val for val in index_cells if val in test_cells])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c947afd",
   "metadata": {},
   "source": [
    "### Train and evaluate using k-fold cross validation with splits on the cell level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c67eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to print the epoch every 20 so we can monitor progress without loads of output\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Finished epoch {epoch}\")\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddf09d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which target you want to train for (refer to cap_df)\n",
    "target_idx = 0\n",
    "\n",
    "# Create some lists to store the scores from model evaluation\n",
    "kf_train_scores = []\n",
    "kf_test_scores = []\n",
    "\n",
    "\n",
    "# Instantiate a custom k-fold generator\n",
    "n_folds = 5\n",
    "k_fold_generator = tools.kfold_gen(train_cells, X_train_index, n_folds=n_folds)\n",
    "\n",
    "# Print the results of iterating through it - should give you n_folds outputs\n",
    "for i in range(n_folds):\n",
    "    print(f\"#### Fold {i+1} ####\")\n",
    "    kf_train_indices, kf_test_indices = next(k_fold_generator)\n",
    "    # Print the number of \"instances\" associated with the train and test indices\n",
    "    print(f\"{len(kf_train_indices)} training instances\")\n",
    "    print(f\"{len(kf_test_indices)} test instances\")\n",
    "    print()\n",
    "    \n",
    "    # Extract the k-fold data from the train arrays\n",
    "    X_train_kf, y_train_kf = X_train[kf_train_indices], y_train[kf_train_indices]\n",
    "    X_test_kf, y_test_kf = X_train[kf_test_indices], y_train[kf_test_indices]\n",
    "    \n",
    "    # Scaling\n",
    "    X_train_kf, _, X_test_kf = scaler_3d(X_train_kf, X_test_kf, X_test_kf, scaler_type='robust', return_scaler=False)\n",
    "    \n",
    "    # Create a model instance\n",
    "    model = models.build_convnet_model(X_in=X_train_kf, loss='mse', n_outputs=1)\n",
    "    progress_callback = MyCallback()\n",
    "    callbacks = [LearningRateScheduler(tools.lr_scheduler, verbose=0), progress_callback]\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_kf, \n",
    "                        y_train_kf[:, target_idx],\n",
    "                        callbacks=callbacks,\n",
    "                        batch_size=512,\n",
    "                        epochs=100,    \n",
    "                        shuffle=True,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # You could save the model here if you wanted\n",
    "    # TODO\n",
    "    \n",
    "    # Evaluate the model on the k-fold train and test set. Add scores to lists.\n",
    "    kf_train_scores.append(model.evaluate(X_train_kf, y_train_kf[:, target_idx]))\n",
    "    kf_test_scores.append(model.evaluate(X_test_kf, y_test_kf[:, target_idx]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bfa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a8062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c4d8612",
   "metadata": {},
   "source": [
    "## Template code for running without k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33bb5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.build_convnet_model(X_in=X_train_sc, loss='mse', n_outputs=1)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7973c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "callbacks = [LearningRateScheduler(tools.lr_scheduler, verbose=0)]\n",
    "\n",
    "history = model.fit(X_train_sc, \n",
    "                    y_train,\n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=512,\n",
    "                    epochs=200,    \n",
    "                    shuffle=True,\n",
    "                    verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70daf6d",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d907092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_convnet_model(n_outputs=1)\n",
    "\n",
    "target_idx = 2\n",
    "verbose = 0\n",
    "callbacks = [LearningRateScheduler(lr_scheduler, verbose=verbose)]\n",
    "history = model.fit(X_train_sc, \n",
    "                    y_train[:, target_idx],\n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=512,\n",
    "                    epochs=200,    \n",
    "                    shuffle=True,\n",
    "                    verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf247e8",
   "metadata": {},
   "source": [
    "### Evaluate the trained model on train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b42f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_sc, y_train[:, target_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6df501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_sc, y_test[:, target_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val_sc, y_val[:, target_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee73051",
   "metadata": {},
   "source": [
    "### Train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.plot(model.predict(X_train_sc))\n",
    "plt.plot(y_train[:, target_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3261b",
   "metadata": {},
   "source": [
    "### Val predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.plot(model.predict(X_val_sc))\n",
    "plt.plot(y_val[:, target_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe34105",
   "metadata": {},
   "source": [
    "### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1803b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.plot(model.predict(X_test_sc))\n",
    "plt.plot(y_test[:, target_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
