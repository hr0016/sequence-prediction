{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391d73a3",
   "metadata": {},
   "source": [
    "## Get the IR data from Baumhofer\n",
    "This notebook is taking the sparse experimental IR data that we have from the Baumhofer dataset and applying interpolation.<br>\n",
    "The final objective of this part of the processing is to get the \"elbows equivalent\" of the prediction targets we have for the capacity, for the first 100 cycles for every cell.<br>\n",
    "\n",
    "This will allow us to train the 1D CNN model to predict the following:\n",
    "- Cycles until elbow onset\n",
    "- Cycles until elbow point\n",
    "- The amount the IR will rise between the current cycle and the cycle at which elbow onset occurs\n",
    "- The amount the IR will rise between the current cycle and the cycle at which elbow point occurs\n",
    "\n",
    "There is one cell (030) that only contains 2 IR data points, so we will not be able to use this for training/predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65867bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import pchip_interpolate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.signal import medfilt\n",
    "import tensorflow as tf\n",
    "\n",
    "from baumhofer_utils import *\n",
    "from knee_finder import KneeFinder\n",
    "\n",
    "# Load the params_dict from the knee_finder directory\n",
    "with open(\"./data/params_dict.pkl\", 'rb') as a_file:\n",
    "    params_dict = pickle.load(a_file)\n",
    "del a_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0f338",
   "metadata": {},
   "source": [
    "### Load the experimental IR data we have from Baumhofer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77605f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/german_IR.pkl\", \"rb\") as a_file:\n",
    "    ir_data = pickle.load(a_file)\n",
    "del a_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a237c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary with the correct cell names\n",
    "ir_dict = {cell: {'IR': None} for cell in [str(i).zfill(3) for i in range(2, 50)]}\n",
    "\n",
    "# Populate ir_dict with the data, using the correct keys\n",
    "for cell_ID, index in zip(ir_dict.keys(), ir_data.keys()):\n",
    "    ir_dict[cell_ID]['IR'] = np.vstack((ir_data[index]['cycles'], ir_data[index]['IR'])).T\n",
    "    \n",
    "del cell_ID, index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4060b4",
   "metadata": {},
   "source": [
    "### Look at the IR data - some cells have very few points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ddfa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in ir_dict:\n",
    "    if ir_dict[cell]['IR'].shape[0] < 5:\n",
    "        plt.plot(ir_dict[cell]['IR'][:,0], ir_dict[cell]['IR'][:,1], '*-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fab456",
   "metadata": {},
   "source": [
    "### PCHIP interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b016cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the interpolation and store results in a dictionary\n",
    "ir_interp = {cell: {'IR': None} for cell in ir_dict}\n",
    "\n",
    "for cell in ir_dict.keys():\n",
    "    x_observed = ir_dict[cell]['IR'][:,0]\n",
    "    y_observed = ir_dict[cell]['IR'][:,1]\n",
    "    # Get an array of integer cycle numbers from zero to the end\n",
    "    x_cont = np.arange(1, x_observed[-1] + 1)\n",
    "    y_interp = pchip_interpolate(x_observed, y_observed, x_cont)\n",
    "    \n",
    "    ir_interp[cell]['IR'] = np.vstack((x_cont, y_interp)).T\n",
    "    \n",
    "del x_observed, y_observed, x_cont, y_interp, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6df84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results on 2 figures, because there are 48 cells\n",
    "\n",
    "fig, ax = plt.subplots(5, 5)\n",
    "for i, cell in enumerate(list(ir_dict.keys())[0:24]):\n",
    "        \n",
    "    ax.flatten()[i].scatter(ir_dict[cell]['IR'][:,0], ir_dict[cell]['IR'][:,1])\n",
    "    ax.flatten()[i].plot(ir_interp[cell]['IR'][:,0], ir_interp[cell]['IR'][:,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(5, 5)\n",
    "for i, cell in enumerate(list(ir_dict.keys())[24:]):\n",
    "        \n",
    "    ax.flatten()[i].scatter(ir_dict[cell]['IR'][:,0], ir_dict[cell]['IR'][:,1])\n",
    "    ax.flatten()[i].plot(ir_interp[cell]['IR'][:,0], ir_interp[cell]['IR'][:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f8efe",
   "metadata": {},
   "source": [
    "### Remove cell 030 before finding elbows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e96ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ir_interp['030']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd37947",
   "metadata": {},
   "source": [
    "### Fix dodgy values in 026 interpolated curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1dd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_interp['026']['IR'][0:20, 1] = ir_interp['026']['IR'][20, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a3fc8",
   "metadata": {},
   "source": [
    "### Generate Targets - Use KneeFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12cefb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knee_and_eol_results(parent_dict, params_dict, src='baumhofer', mode='knee', filter_data=False, truncate=False, normalise=False, to_plot=False):\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Determine data_type from \"mode\" argument\n",
    "    if mode == \"knee\":\n",
    "        data_type = \"capacity\"\n",
    "    elif mode == \"elbow\":\n",
    "        data_type = \"IR\"\n",
    "           \n",
    "\n",
    "    # Create a DataFrame whose indices are cell names\n",
    "    df = pd.DataFrame(columns=['onset', 'point', 'EOL', 'onset_y', 'point_y'], index=parent_dict.keys())\n",
    "    \n",
    "    if to_plot:\n",
    "        # Make one plot for each curve. Have a square array of subplots\n",
    "        num_plots = int(np.sqrt(len(parent_dict.keys()))) + 1\n",
    "        fig, ax = plt.subplots(num_plots, num_plots)\n",
    "\n",
    "    for i, cell in enumerate(list(parent_dict.keys())):\n",
    "                \n",
    "        # Get the capacity data from the dictionary\n",
    "        arr = copy.deepcopy(parent_dict[cell][data_type])\n",
    "               \n",
    "        # Introduce more readable variable names\n",
    "        cycles = arr[:,0]\n",
    "        orig_values = arr[:,1]\n",
    "        \n",
    "        if normalise:\n",
    "            values = orig_values / np.max(orig_values)\n",
    "        else:\n",
    "            values = orig_values\n",
    "        \n",
    "        # Filter the data if specified\n",
    "        if filter_data:\n",
    "            values = medfilt(values, 5)\n",
    "                    \n",
    "        # Create an instance of KneeFinder\n",
    "        kf = KneeFinder(cycles, values, mode=mode, truncate=truncate)            \n",
    "        \n",
    "        # Call the KneeFinder methods to find onset, point and EOL\n",
    "        kf.set_params_using_dict(params_dict, data_type=data_type, src=src)\n",
    "        kf.find_onset_and_point()\n",
    "        kf.find_eol()\n",
    "        \n",
    "        # Populate the DataFrame with the identified onset and point\n",
    "        df.loc[cell]['onset'] = kf.onset\n",
    "        df.loc[cell]['point'] = kf.point\n",
    "        df.loc[cell]['EOL'] = kf.eol_cycle\n",
    "        \n",
    "        # Get the y values on the original scale, if normalise is True\n",
    "        if normalise:\n",
    "            df.loc[cell]['onset_y'] = kf.onset_y * np.max(orig_values)\n",
    "            df.loc[cell]['point_y'] = kf.point_y * np.max(orig_values)\n",
    "            # Multiply the fit values to recover original scale\n",
    "            kf.exp_fit = kf.exp_fit * max(orig_values)\n",
    "            if truncate:\n",
    "                kf.sig_fit = kf.sig_fit * max(orig_values)\n",
    "        else:\n",
    "            df.loc[cell]['onset_y'] = kf.onset_y\n",
    "            df.loc[cell]['point_y'] = kf.point_y\n",
    "\n",
    "    \n",
    "        if to_plot:\n",
    "            ax.flatten()[i].plot(cycles, orig_values)\n",
    "\n",
    "            ax.flatten()[i].axvline(kf.onset)\n",
    "            ax.flatten()[i].axvline(kf.point)\n",
    "            ax.flatten()[i].plot(kf.x_cont[kf.indices], kf.exp_fit)\n",
    "            #if truncate:\n",
    "                #ax.flatten()[i].plot(kf.x_cont, kf.sig_fit)        \n",
    "            if kf.eol_reached:\n",
    "                ax.flatten()[i].axvline(kf.eol_cycle, color='red')\n",
    "            ax.flatten()[i].set_title(cell)\n",
    "\n",
    "    if to_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2060bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elbows = get_knee_and_eol_results(parent_dict=ir_interp,\n",
    "                                     params_dict=params_dict,\n",
    "                                     src='baumhofer',\n",
    "                                     mode='elbow',\n",
    "                                     filter_data=False,\n",
    "                                     truncate=False,\n",
    "                                     normalise=False,\n",
    "                                     to_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bf62d",
   "metadata": {},
   "source": [
    "### Try fitting the line plus exponential to the data prior to generating the y targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7237a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a cell\n",
    "cell = '009'\n",
    "x = copy.deepcopy(ir_interp[cell]['IR'][:,0])\n",
    "y = copy.deepcopy(ir_interp[cell]['IR'][:,1])\n",
    "\n",
    "kf = KneeFinder(cycles=x, y=y, truncate=False, mode='elbow')\n",
    "kf.set_params_using_dict(params_dict, data_type='IR', src='baumhofer')\n",
    "kf.find_onset_and_point()\n",
    "y_line_exp = kf.exp_fit\n",
    "\n",
    "plt.plot(x, y, label='PCHIP interpolated')\n",
    "plt.plot(x, y_line_exp, label='Line + exp applied to PCHIP interpolated curve')\n",
    "plt.xlabel(\"Cycle number\")\n",
    "plt.ylabel(\"IR\")\n",
    "plt.legend()\n",
    "plt.title(f\"Cell {cell}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf2e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the line plus exponential to every fit and save the results\n",
    "# in a new dictionary to easily compare the resulting target arrays\n",
    "ir_fix = copy.deepcopy(ir_interp)\n",
    "\n",
    "for cell in ir_fix:\n",
    "    x = ir_fix[cell]['IR'][:,0]\n",
    "    y = ir_fix[cell]['IR'][:,1]\n",
    "\n",
    "    kf = KneeFinder(cycles=x, y=y, truncate=False, mode='elbow')\n",
    "    kf.set_params_using_dict(params_dict, data_type='IR', src='baumhofer')\n",
    "    kf.find_onset_and_point()\n",
    "    y_line_exp = kf.exp_fit\n",
    "    \n",
    "    # Replace the PCHIP interpolation with the line plus exponential fit to the PCHIP interpolation\n",
    "    ir_fix[cell]['IR'][:,1] = y_line_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11951e",
   "metadata": {},
   "source": [
    "### Get the y array of 5 targets for each cycle\n",
    "**Notice that I've removed the EOL, since not all cells die by IR 200% and we will use 80% capacity EOL anyway**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a3b5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_IR_target_array(parent_dict, key, cell_ID, df, lo_idx, hi_idx):\n",
    "    '''\n",
    "    For a particular cell_ID in parent_dict, generate an array with 5 columns.\n",
    "    \n",
    "    These columns represent:\n",
    "    - Number of cycles remaining until elbow onset\n",
    "    - Number of cycles remaining until elbow point\n",
    "    - IR increase until elbow onset\n",
    "    - IR increase until elbow point\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_dict (type: dict)\n",
    "        Dictionary whose keys are cell IDs, containing 2D cycle/IR array in a key\n",
    "        \n",
    "    key (type: str)\n",
    "        Dictionary key that is used to identify the cycle/IR 2D array.\n",
    "        \n",
    "    cell_ID (type: str)\n",
    "        Cell identifier string used to specify the keys of parent_dict to extract cell data.\n",
    "        \n",
    "    df (type: pd.DataFrame)\n",
    "        A DataFrame containing, for each cell, 4 values (cycle number for onset, cycle number for point, IR at onset and IR at point).\n",
    "        This is obtained using the function \"get_knee_and_eol_results\"    \n",
    "    \n",
    "    lo_idx (type: int)\n",
    "        Index in the capacity array that corresponds to the first cycle of time series data.\n",
    "        This is needed if you have taken cycles 2 to 101 for each cell, for example.\n",
    "    \n",
    "    hi_idx (type: int)\n",
    "        Index in the capacity array that corresponds to the last cycle of time series data.\n",
    "        This is needed if you have taken cycles 2 to 101 for each cell, for example.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Extract the 2D array of cycles/interpolated capacity values from the dictionary\n",
    "    ir_arr = parent_dict[cell_ID][key]\n",
    "    ir_arr = ir_arr[lo_idx:hi_idx+1]\n",
    "\n",
    "    # Create a DataFrame so we can explicitly refer to the column names for assignment\n",
    "    result = pd.DataFrame(np.zeros(shape=(ir_arr.shape[0], 4), dtype=float),\n",
    "                          index=ir_arr[:,0].astype(int),\n",
    "                          columns=['tto', 'ttp', 'deg_o', 'deg_p'])\n",
    "\n",
    "    # Populate the result DataFrame with values\n",
    "    result['tto'] = df.at[cell_ID, \"onset\"] - ir_arr[:,0]\n",
    "    result['ttp'] = df.at[cell_ID, \"point\"] - ir_arr[:,0]\n",
    "    #result['tte'] = df.at[cell_ID, \"EOL\"] - ir_arr[:,0]\n",
    "    result['deg_o'] = df.at[cell_ID, \"onset_y\"] - ir_arr[:,1]\n",
    "    result['deg_p'] = df.at[cell_ID, \"point_y\"] - ir_arr[:,1]\n",
    "    \n",
    "\n",
    "    # Convert the DataFrame to a numpy array\n",
    "    result_arr = result.to_numpy(copy=True)\n",
    "    \n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b56762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the cell IDs\n",
    "cells = list(ir_interp.keys())\n",
    "\n",
    "# Instantiate index values to be passed to create_y_target_array.\n",
    "# These are the indices for the capacity arrays for which the cycle\n",
    "# numbers match those whose time series data we are using.\n",
    "lo_idx = 2\n",
    "hi_idx = 100\n",
    "\n",
    "# Create the y target array for all cells, for the first N cycles of each cell\n",
    "# THIS USES THE PCHIP INTERPOLATION DATA DIRECTLY\n",
    "y_arr_IR = np.vstack([create_y_IR_target_array(parent_dict=ir_interp, key='IR', cell_ID=cell, df=df_elbows, lo_idx=lo_idx, hi_idx=hi_idx) for cell in cells])\n",
    "\n",
    "# THIS USES THE ATTEMPTED FIX\n",
    "y_arr_IR_fix = np.vstack([create_y_IR_target_array(parent_dict=ir_fix, key='IR', cell_ID=cell, df=df_elbows, lo_idx=lo_idx, hi_idx=hi_idx) for cell in cells])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b165ab4",
   "metadata": {},
   "source": [
    "### Take a look at an individual cell, with onset and point annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa289e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1b4de0afa20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = '009'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ir_fix[cell]['IR'][:,0], ir_fix[cell]['IR'][:,1])\n",
    "ax.axvline(df_elbows.loc[cell, 'onset'])\n",
    "ax.axvline(df_elbows.loc[cell, 'point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb914d8a",
   "metadata": {},
   "source": [
    "### Compare the PCHIP interpolation and PCHIP + line_exp fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cf004fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(y_arr_IR[:,2], alpha=0.4, label='IR rise until onset (from PCHIP interpolation)')\n",
    "ax[0].plot(y_arr_IR_fix[:,2], label='IR rise until onset (from line_exp fit applied to PCHIP interpolation)')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(y_arr_IR[:,3], alpha=0.4, label='IR rise until point (from PCHIP interpolation)')\n",
    "ax[1].plot(y_arr_IR_fix[:,3], label='IR rise until point (from line_exp fit applied to PCHIP interpolation)')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
